---
title: "Bayesian Logistic Regression in JAGS"
author: "Joaquín Martínez-Minaya"
date: "`r Sys.Date()`"
linestretch: "1.5"

output:   
  bookdown::html_document2:
    df_print: paged
    code_folding: show
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(runjags)
library(coda)
library(readxl)
library(dplyr)
library(ggplot2)
```

# Introduction

This document illustrates how to implement Bayesian logistic regression using the `runjags` package. The goal is to model the relationship between myocardial infarction (MI) and two predictors: age and systolic blood pressure (SBP).


# Problem Description

<div style="float: right; margin-right: 20px; width: 50%;">
  ```{r, echo=FALSE, out.width='100%'}
  knitr::include_graphics('heart.png')
  ```
</div>


This study is inspired by an example which investigates the relationship between myocardial infarction and several clinical variables. The dataset and problem are adapted from: Broemeling, L. D. (2013). *Bayesian Methods in Epidemiology*. CRC Press.



In particular, we examines the relationship between myocardial infarction (MI) and two covariates, age and systolic blood pressure (SBP). Specifically:

- **Age**:
  - Represented by the variable `age`, categorized as:
    - `age60 = 1`: Patients aged \(\geq 60\) years.
    - `age60 = 0`: Patients aged \(< 60\) years.

- **Systolic Blood Pressure (SBP)**:
  - Represented by the variable `SBP`, categorized as:
    - `SBP140 = 1`: SBP \(\geq 140\) mmHg.
    - `SBP140 = 0`: SBP \(< 140\) mmHg.


The response variable \(y\) represents the occurrence of **myocardial infarction (MI)**:

  - \(y = 1\): MI occurrence (heart attack).

  - \(y = 0\): No MI occurrence.

The goal of the analysis is to assess how `age60` and `SBP140` influence the probability of MI. 
```{r}
data_hattack <- readxl::read_xlsx("heartattack.xlsx")
data_hattack$sbp140 <- as.factor(data_hattack$sbp140)
data_hattack$age60 <- as.factor(data_hattack$age60)
data_hattack
```


# Model Specification

In this study, we use a logistic regression model to assess the relationship between myocardial infarction (MI) and the categorical covariates age60 and sbp140. The model is specified as follows:

**likelihood:**

\begin{eqnarray}
y_i & \sim & \text{Ber}(\pi_i) \,, i = 1, \ldots, 450, \nonumber \\
\text{logit}(\theta_i) & = & \beta_0 + \beta_1 \cdot \text{age60}_i + \beta_2 \cdot \text{SBP140}_i,
\end{eqnarray}
where:

- \(\pi_i\): Probability of MI for patient \(i\).

- \(\text{age60}_i\): Binary indicator for age (\(1\) if \(\geq 60\) years, \(0\) otherwise).

- \(\text{SBP140}_i\): Binary indicator for SBP (\(1\) if \(\geq 140\) mmHg, \(0\) otherwise).

- \(\beta_0\): Intercept, representing the baseline log-odds of MI when \(\text{age60}_i = 0\) and \(\text{SBP140}_i = 0\).

- \(\beta_1\): Log-odds ratio for age (\( \geq 60 \) vs. \( < 60 \)).

- \(\beta_2\): Log-odds ratio for SBP (\( \geq 140 \) mmHg vs. \( < 140 \) mmHg).

**Priors:**

In the Bayesian framework, prior distributions are assigned to the model parameters to express prior beliefs about their values. For this model, we use non-informative priors to reflect minimal prior knowledge:

- \(\beta_0 \sim \mathcal{N}(0, 10^6)\): A normal distribution with mean 0 and very large variance, representing vague prior information about the intercept.
- \(\beta_1 \sim \mathcal{N}(0, 10^6)\): A normal distribution with mean 0 and very large variance, representing vague prior information about the effect of age.
- \(\beta_2 \sim \mathcal{N}(0, 10^6)\): A normal distribution with mean 0 and very large variance, representing vague prior information about the effect of SBP.

These priors allow the data to dominate the posterior inference, ensuring that the results are primarily driven by the observed data.



# JAGS Implementation

This section outlines the implementation of the Bayesian logistic regression model in JAGS, including model specification, data preparation, running the analysis with `runjags`, and performing convergence diagnostics. 

## Model

The model specifies the relationship between myocardial infarction (MI) and two covariates, `age60` and `sbp140`, using a logistic regression framework. The response variable \(y\) follows a Bernoulli distribution, and the log-odds of \(y\) are modeled as a linear function of the covariates:

```{r, echo=TRUE}
# JAGS model
model_string <- "
model {
  for (i in 1:N) {
    y[i] ~ dbern(pi[i])
    logit(pi[i]) <- beta0 + beta1 * age60[i] + beta2 * sbp140[i]
  }
  # Priors for regression coefficients
  beta0 ~ dnorm(0, 0.001)  # Intercept
  beta1 ~ dnorm(0, 0.001)  # Effect of age60
  beta2 ~ dnorm(0, 0.001)  # Effect of sbp140
}"
```

## Data Preparation

We use the `data_hattack` dataset, which contains information on the response variable (`y`), age in binary form (`age60`), SBP in binary form (`sbp140`), and their continuous counterparts (`age` and `sbp`). The data is structured to match the model requirements.

```{r}
# Prepare data for JAGS
data_list <- list(
  N = 400,  # Total number of observations
  y = data_hattack$y,  # Response variable: MI occurrence (1 or 0)
  age60 = as.numeric(data_hattack$age60),  # Age
  sbp140 = as.numeric(data_hattack$sbp140)  # SBP
)

# Define initial values for MCMC chains
inits <- list(
  list(beta0 = 0, beta1 = 0, beta2 = 0),
  list(beta0 = 0.5, beta1 = -0.5, beta2 = 0.5),
  list(beta0 = -0.5, beta1 = 0.5, beta2 = -0.5)
)
```


## Bayesian Inference with `runjags`

Before running the Bayesian inference algorithm, it is essential to understand the key parameters used to configure the MCMC process:

1. **`n.chains`**: Number of independent MCMC chains. Running multiple chains ensures better convergence diagnostics and robustness of results.
   - **Recommendation**: Use 3-4 chains for most models.

2. **`burnin`**: Number of initial samples discarded to allow the chains to stabilize and converge to the posterior distribution.
   - **Recommendation**: Set this to 10% of the total iterations, adjusting based on model complexity.

3. **`sample`**: Number of post-burn-in samples retained for posterior inference.
   - **Recommendation**: At least 10,000 samples are generally sufficient for robust posterior estimation.

4. **`adapt`**: Number of iterations for the sampler to adapt to the model. This optimizes the efficiency of the sampling algorithm (This is something just used in `JAGS`).
   - **Recommendation**: Use 1000 as a default; higher values may be necessary for more complex models.

5. **`thin`**: Interval at which samples are retained. For instance, `thin = 2` retains every second sample, reducing autocorrelation.
   - **Recommendation**: For well-mixing chains, use `thin = 1`. Increase if chains show high autocorrelation.



Now, we use these parameters to configure and run the Bayesian inference using `runjags`:

```{r, message = FALSE, warning = FALSE}
# Run the JAGS model
results <- run.jags(
  model = model_string,
  data = data_list,
  inits = inits,
  monitor = c("beta0", "beta1", "beta2"),
  n.chains = 3,       # Number of parallel MCMC chains
  burnin = 1000,      # Number of iterations to discard for burn-in
  sample = 10000,     # Number of iterations to keep for posterior analysis
  adapt = 1000,       # Number of iterations for adapting the sampler
  thin = 5            # Thinning interval
)

            # Summarize the results
summary(results) %>% 
  as.data.frame(.) %>%
  dplyr::select( Lower95, Median, Upper95, Mean, SD, SSeff, psrf) %>%
  round(., 4)
```


## Convergence Diagnostics {.tabset}

After running the MCMC simulation, it is crucial to evaluate whether the chains have converged and provide reliable posterior estimates. Below, we perform convergence diagnostics and assess the quality of the MCMC output.

### **Trace Plots**:
   - Visualize the behavior of the chains over iterations.
   - Well-mixed chains without apparent trends indicate convergence.

```{r}
# Extract MCMC samples
mcmc_samples <- as.mcmc.list(results)

# 1. Trace Plots
plot(mcmc_samples, col = "blue", main = "Trace Plots for MCMC Chains")
```


### **Gelman-Rubin Diagnostic**:
   - Compares within-chain and between-chain variability.
   - A Gelman-Rubin statistic close to 1 suggests convergence.

```{r}
gelman_diag <- gelman.diag(mcmc_samples)
print(gelman_diag)
```


### **Effective Sample Size (ESS)**:
   - Measures the number of independent samples in the MCMC output.
   - Higher ESS values indicate better mixing of chains.

```{r}
ess <- effectiveSize(mcmc_samples)
print(ess)
```








# Interpreting results
In this section, we calculate the odds ratios for age60 and sbp140 by transforming the posterior samples of the coefficients using the exponential function. The odds ratio represents the change in the odds of myocardial infarction for a one-unit increase in the predictor.

```{r}
# Calculate the odds ratios by transforming the posterior samples
odds_ratios <- lapply(mcmc_samples, function(chain) {
  exp_chain <- exp(chain[, c("beta1", "beta2")])
  as.data.frame(exp_chain)
})

names(odds_ratios[[1]])  <- paste0("odds_ratio_", names(odds_ratios[[1]]))

# Pivot the odds ratios data to long format for easier plotting
odds_ratios_long <- odds_ratios[[1]] %>%
  tidyr::pivot_longer(cols = 1:2, names_to = "parameter", values_to = "odds_ratio")


# Plot density of each odds ratio using ggplot2
ggplot(odds_ratios_long, aes(x = odds_ratio, fill = parameter)) +
  geom_density(alpha = 0.5) +
  labs(title = "Posterior Density of Odds Ratios",
       x = "Odds Ratio",
       y = "Density",
       fill = "Parameter") +
  theme_minimal()
  
```


The plot above shows the posterior densities of the odds ratios for age60 and sbp140. Higher density regions indicate more probable values for the odds ratios.

```{r}
# Summarize the odds ratios for each parameter
summary_odds_ratios_each <- odds_ratios_long %>%
  group_by(parameter) %>%
  summarise(
    median = median(odds_ratio),                  # Median of the odds ratio
    mean = mean(odds_ratio),                      # Mean of the odds ratio
    sd = sd(odds_ratio),                          # Standard deviation of the odds ratio
    lower95 = quantile(odds_ratio, 0.025),        # 2.5th percentile (lower 95% credible interval)
    upper95 = quantile(odds_ratio, 0.975),        # 97.5th percentile (upper 95% credible interval)
    min = min(odds_ratio),                        # Minimum value of the odds ratio
    max = max(odds_ratio)                         # Maximum value of the odds ratio
  )

# Print the summary
print(summary_odds_ratios_each)
```

The interpretation of the parameters is as follows:

- For the odds ratio of age60 with a posterior median of 1.926, the implication is that **the odds of a heart attack for a person older than 60 years is approximately 1.926 times the odds of a heart attack for a person younger than 60**. 

- For the odds ratio of sbp140, the median is 2.773, implying that **the odds of a heart attack for a person with a systolic blood pressure greater than 140 mmHg are approximately 2.773 times the odds for a person with lower blood pressure**. 

- The 95% credible intervals for both odds ratios do not include the value 1, suggesting that both age and SBP have a relevant effect on the occurrence of a heart attack.

REMEMBER: this is a simulated dataset. Don't freak out if your blood preasure es greater than 140 mmHg or your age is greater than 60.


# Predictions

There are four new people with the following characteristics:

- Individual1: He is under 60, with 135 mmHg

- Invididual2: She is over 60, with 141 mmHg

- Individual3: She is under 60, with 150 mmHg

- Individual4: she is over 60, with 120 mmHg

Could you predict the probability for all these people to have a heart attack?

